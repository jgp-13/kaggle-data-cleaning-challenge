{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Challenge - Inconsistent data entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
    "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
   },
   "source": [
    "### All days of the challange:\n",
    "\n",
    "* [Day 1: Handling missing values](./nb1-data-cleaning-challenge-handling-missing-values.ipynb)\n",
    "* [Day 2: Scaling and normalization](./nb2-data-cleaning-challenge-scale-and-normalize-data.ipynb)\n",
    "* [Day 3: Parsing dates](./nb3-data-cleaning-challenge-parsing-dates.ipynb)\n",
    "* [Day 4: Character encodings](./nb4-data-cleaning-challenge-character-encodings.ipynb)\n",
    "* [Day 5: Inconsistent Data Entry](./nb5-data-cleaning-challenge-inconsistent-data-entry.ipynb)\n",
    "___\n",
    "\n",
    "Welcome to day 5 of the 5-Day Data Challenge! (Can you believe it's already been five days??) Today, we're going to learn how to clean up inconsistent text entries. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n",
    "\n",
    "> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n",
    "\n",
    "Here's what we're going to do today:\n",
    "\n",
    "* [Get our environment set up](#Get-our-environment-set-up)\n",
    "* [Do some preliminary text pre-processing](#Do-some-preliminary-text-pre-processing)\n",
    "* [Use fuzzy matching to correct inconsistent data entry](#Use-fuzzy-matching-to-correct-inconsistent-data-entry)\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
    "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
   },
   "source": [
    "## Get our environment set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
    "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
   },
   "source": [
    "The first thing we'll need to do is load in the libraries we'll be using. Not our datasets, though: we'll get to those later!\n",
    "\n",
    "> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
    "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f"
   },
   "outputs": [],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpful modules\n",
    "### fuzzywuzzy is deprecated ###\n",
    "#import fuzzywuzzy\n",
    "#from fuzzywuzzy import process\n",
    "import thefuzz\n",
    "from thefuzz import process\n",
    "import chardet\n",
    "\n",
    "# Handling directories\n",
    "import os\n",
    "import kaggle_cleaning\n",
    "from kaggle_cleaning.config import RAW_DATA_DIR, CLEAN_DATA_DIR\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5169ae8c-6210-400a-ace2-e5fbe00378fc",
    "_uuid": "ed09d242e94e22f1bac2dc446d7545b1d1f5d5c5"
   },
   "source": [
    "When I tried to read in the `PakistanSuicideAttacks Ver 11 (30-November-2017).csv`file the first time, I got a character encoding error, so I'm going to quickly check out what the encoding should be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ee54b6ee-0869-438a-9b6f-57c6d67f923f",
    "_uuid": "d2578d4d4bc7e42f5ab6157d9c3eb40e68d42e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.BufferedReader'>\n",
      "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# look at the first ten thousand bytes to guess the character encoding\n",
    "raw_pak = os.path.join(RAW_DATA_DIR, 'PakistanSuicideAttacks Ver 11 (30-November-2017).csv')\n",
    "with open(raw_pak, 'rb') as rawdata:\n",
    "    print(type(rawdata))\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "\n",
    "# check what the character encoding might be\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a60be35-cd57-4dcc-9b98-c365de041332",
    "_uuid": "71d00770de8e42e926d8dc5a3a8b48b2c368ea43"
   },
   "source": [
    "And then read it in with the correct encoding. (If this look unfamiliar to you, check out [yesterday's challenge](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/).) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0f40ed87-fc61-4a61-b230-6af1f4618114",
    "_uuid": "c82584427932f3f0ccd21c7d1eca92f62476ed0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunday-November 19-1995</td>\n",
       "      <td>25 Jumaada al-THaany 1416 A.H</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islamabad</td>\n",
       "      <td>33.7180</td>\n",
       "      <td>73.0718</td>\n",
       "      <td>Capital</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.835</td>\n",
       "      <td>60.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monday-November 6-2000</td>\n",
       "      <td>10 SHa`baan 1421 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>24.9918</td>\n",
       "      <td>66.9911</td>\n",
       "      <td>Sindh</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.770</td>\n",
       "      <td>74.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday-May 8-2002</td>\n",
       "      <td>25 safar 1423 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7:45 AM</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>24.9918</td>\n",
       "      <td>66.9911</td>\n",
       "      <td>Sindh</td>\n",
       "      <td>...</td>\n",
       "      <td>Christian</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5 Kg</td>\n",
       "      <td>1.Jinnah Postgraduate Medical Center 2. Civil ...</td>\n",
       "      <td>31.460</td>\n",
       "      <td>88.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Friday-June 14-2002</td>\n",
       "      <td>3 Raby` al-THaany 1423 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:10:00 AM</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>24.9918</td>\n",
       "      <td>66.9911</td>\n",
       "      <td>Sindh</td>\n",
       "      <td>...</td>\n",
       "      <td>Christian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.430</td>\n",
       "      <td>88.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Friday-July 4-2003</td>\n",
       "      <td>4 Jumaada al-awal 1424 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>30.2095</td>\n",
       "      <td>67.0182</td>\n",
       "      <td>Baluchistan</td>\n",
       "      <td>...</td>\n",
       "      <td>Shiite</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.CMH Quetta \\n2.Civil Hospital 3. Boland Medi...</td>\n",
       "      <td>33.120</td>\n",
       "      <td>91.616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S#                     Date                   Islamic Date Blast Day Type  \\\n",
       "0   1  Sunday-November 19-1995  25 Jumaada al-THaany 1416 A.H        Holiday   \n",
       "1   2   Monday-November 6-2000           10 SHa`baan 1421 A.H    Working Day   \n",
       "2   3     Wednesday-May 8-2002              25 safar 1423 A.H    Working Day   \n",
       "3   4      Friday-June 14-2002     3 Raby` al-THaany 1423 A.H    Working Day   \n",
       "4   5       Friday-July 4-2003     4 Jumaada al-awal 1424 A.H    Working Day   \n",
       "\n",
       "  Holiday Type         Time       City  Latitude Longitude     Province  ...  \\\n",
       "0      Weekend          NaN  Islamabad   33.7180   73.0718      Capital  ...   \n",
       "1          NaN          NaN    Karachi   24.9918   66.9911        Sindh  ...   \n",
       "2          NaN      7:45 AM   Karachi    24.9918   66.9911        Sindh  ...   \n",
       "3          NaN  11:10:00 AM    Karachi   24.9918   66.9911        Sindh  ...   \n",
       "4          NaN          NaN     Quetta   30.2095   67.0182  Baluchistan  ...   \n",
       "\n",
       "  Targeted Sect if any Killed Min Killed Max Injured Min Injured Max  \\\n",
       "0                  NaN       14.0       15.0         NaN          60   \n",
       "1                  NaN        NaN        3.0         NaN           3   \n",
       "2            Christian       13.0       15.0        20.0          40   \n",
       "3            Christian        NaN       12.0         NaN          51   \n",
       "4               Shiite       44.0       47.0         NaN          65   \n",
       "\n",
       "  No. of Suicide Blasts Explosive Weight (max)  \\\n",
       "0                   2.0                    NaN   \n",
       "1                   1.0                    NaN   \n",
       "2                   1.0                 2.5 Kg   \n",
       "3                   1.0                    NaN   \n",
       "4                   1.0                    NaN   \n",
       "\n",
       "                                      Hospital Names  Temperature(C)  \\\n",
       "0                                                NaN          15.835   \n",
       "1                                                NaN          23.770   \n",
       "2  1.Jinnah Postgraduate Medical Center 2. Civil ...          31.460   \n",
       "3                                                NaN          31.430   \n",
       "4  1.CMH Quetta \\n2.Civil Hospital 3. Boland Medi...          33.120   \n",
       "\n",
       "   Temperature(F)  \n",
       "0          60.503  \n",
       "1          74.786  \n",
       "2          88.628  \n",
       "3          88.574  \n",
       "4          91.616  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in our dat\n",
    "suicide_attacks = pd.read_csv(raw_pak, \n",
    "                              encoding='Windows-1252')\n",
    "suicide_attacks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83630dd4-6775-4ba5-a290-077c6f503f64",
    "_uuid": "a3f42cea88795426f036e35d30d5c079f3c6152c"
   },
   "source": [
    "Now we're ready to get started! You can, as always, take a moment here to look at the data and get familiar with it. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83630dd4-6775-4ba5-a290-077c6f503f64",
    "_uuid": "a3f42cea88795426f036e35d30d5c079f3c6152c"
   },
   "source": [
    "## Do some preliminary text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83630dd4-6775-4ba5-a290-077c6f503f64",
    "_uuid": "a3f42cea88795426f036e35d30d5c079f3c6152c"
   },
   "source": [
    "For this exercise, I'm interested in cleaning up the \"City\" column to make sure there's no data entry inconsistencies in it. We could go through and check each row by hand, of course, and hand-correct inconsistencies when we find them. There's a more efficient way to do this though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b3d4b17e-77c4-46d8-9681-a94801969b49",
    "_uuid": "4bced8b6f6a985ded2c991f46ed0145ac1d8b722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATTOCK', 'Attock ', 'Bajaur Agency', 'Bannu', 'Bhakkar ', 'Buner',\n",
       "       'Chakwal ', 'Chaman', 'Charsadda', 'Charsadda ', 'D. I Khan',\n",
       "       'D.G Khan', 'D.G Khan ', 'D.I Khan', 'D.I Khan ', 'Dara Adam Khel',\n",
       "       'Dara Adam khel', 'Fateh Jang', 'Ghallanai, Mohmand Agency ',\n",
       "       'Gujrat', 'Hangu', 'Haripur', 'Hayatabad', 'Islamabad',\n",
       "       'Islamabad ', 'Jacobabad', 'KURRAM AGENCY', 'Karachi', 'Karachi ',\n",
       "       'Karak', 'Khanewal', 'Khuzdar', 'Khyber Agency', 'Khyber Agency ',\n",
       "       'Kohat', 'Kohat ', 'Kuram Agency ', 'Lahore', 'Lahore ',\n",
       "       'Lakki Marwat', 'Lakki marwat', 'Lasbela', 'Lower Dir', 'MULTAN',\n",
       "       'Malakand ', 'Mansehra', 'Mardan', 'Mohmand Agency',\n",
       "       'Mohmand Agency ', 'Mohmand agency', 'Mosal Kor, Mohmand Agency',\n",
       "       'Multan', 'Muzaffarabad', 'North Waziristan', 'North waziristan',\n",
       "       'Nowshehra', 'Orakzai Agency', 'Peshawar', 'Peshawar ', 'Pishin',\n",
       "       'Poonch', 'Quetta', 'Quetta ', 'Rawalpindi', 'Sargodha',\n",
       "       'Sehwan town', 'Shabqadar-Charsadda', 'Shangla ', 'Shikarpur',\n",
       "       'Sialkot', 'South Waziristan', 'South waziristan', 'Sudhanoti',\n",
       "       'Sukkur', 'Swabi ', 'Swat', 'Swat ', 'Taftan',\n",
       "       'Tangi, Charsadda District', 'Tank', 'Tank ', 'Taunsa',\n",
       "       'Tirah Valley', 'Totalai', 'Upper Dir', 'Wagah', 'Zhob', 'bannu',\n",
       "       'karachi', 'karachi ', 'lakki marwat', 'peshawar', 'swat'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'City' column\n",
    "cities = suicide_attacks['City'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c11d7808-e677-4ec3-a357-0a3e9bed4cf5",
    "_uuid": "8785e8cc59b40e6ac7a824184132460e22a99f87"
   },
   "source": [
    "Just looking at this, I can see some problems due to inconsistent data entry: 'Lahore' and 'Lahore ', for example, or 'Lakki Marwat' and 'Lakki marwat'.\n",
    "\n",
    "The first thing I'm going to do is make everything lower case (I can change it back at the end if I like) and remove any white spaces at the beginning and end of cells. Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "61651d57-f28c-4b81-bd05-b82720a8ed18",
    "_uuid": "2b604c74492419f89a43262d1f811e272646f9a6"
   },
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "suicide_attacks['City'] = suicide_attacks['City'].str.lower()\n",
    "# remove trailing white spaces\n",
    "suicide_attacks['City'] = suicide_attacks['City'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['islamabad', 'karachi', 'quetta', 'rawalpindi', 'north waziristan',\n",
       "       'kohat', 'attock', 'sialkot', 'lahore', 'swat', 'hangu', 'bannu',\n",
       "       'lasbela', 'malakand', 'peshawar', 'd.i khan', 'lakki marwat',\n",
       "       'tank', 'gujrat', 'charsadda', 'kuram agency', 'shangla',\n",
       "       'bajaur agency', 'south waziristan', 'haripur', 'sargodha',\n",
       "       'nowshehra', 'mohmand agency', 'dara adam khel', 'khyber agency',\n",
       "       'mardan', 'bhakkar', 'orakzai agency', 'buner', 'd.g khan',\n",
       "       'pishin', 'chakwal', 'upper dir', 'muzaffarabad', 'totalai',\n",
       "       'multan', 'lower dir', 'sudhanoti', 'poonch', 'mansehra', 'karak',\n",
       "       'swabi', 'shikarpur', 'sukkur', 'chaman', 'd. i khan', 'khanewal',\n",
       "       'fateh jang', 'taftan', 'tirah valley', 'wagah', 'zhob',\n",
       "       'kurram agency', 'taunsa', 'jacobabad', 'shabqadar-charsadda',\n",
       "       'khuzdar', 'ghallanai, mohmand agency', 'hayatabad',\n",
       "       'mosal kor, mohmand agency', 'sehwan town',\n",
       "       'tangi, charsadda district'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide_attacks['City'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c11e916-981a-41c3-b79f-9ac60521d6a2",
    "_uuid": "29388ff41b320262a8fe17a8f2a347ae919bad7c"
   },
   "source": [
    "Next we're going to tackle more difficult inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "3deb3f1b-80e0-4a94-9bf7-1c9cd4882c18",
    "_uuid": "27aeda660f0e95ccb24bf8c5c1e1d5cfb22be7a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AJK', 'Balochistan', 'Baluchistan', 'Capital', 'FATA', 'Fata',\n",
       "       'KPK', 'Punjab', 'Sindh'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your turn! Take a look at all the unique values in the \"Province\" column. \n",
    "provinces = suicide_attacks['Province'].unique()\n",
    "provinces.sort()\n",
    "provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['capital', 'sindh', 'baluchistan', 'punjab', 'fata', 'kpk', 'ajk',\n",
       "       'balochistan'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then convert the column to lowercase and remove any trailing white spaces\n",
    "suicide_attacks['Province'] = suicide_attacks['Province'].str.lower()\n",
    "suicide_attacks['Province'] = suicide_attacks['Province'].str.strip()\n",
    "suicide_attacks['Province'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a612e0fa-1361-4e8e-a6aa-5008b631d076",
    "_uuid": "3639865348f499faa25b75a46438807ed70d4173"
   },
   "source": [
    "## Use fuzzy matching to correct inconsistent data entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a612e0fa-1361-4e8e-a6aa-5008b631d076",
    "_uuid": "3639865348f499faa25b75a46438807ed70d4173"
   },
   "source": [
    "Alright, let's take another look at the city column and see if there's any more data cleaning we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "8f20fd24-33a4-472d-ba22-be0abc2a1e5b",
    "_uuid": "1408dacdd7b76f306bd1c0c534b991d76243d7cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n",
       "       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n",
       "       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n",
       "       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n",
       "       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n",
       "       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n",
       "       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n",
       "       'mansehra', 'mardan', 'mohmand agency',\n",
       "       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n",
       "       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n",
       "       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n",
       "       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n",
       "       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n",
       "       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n",
       "       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'City' column\n",
    "cities = suicide_attacks['City'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dcbefc7e-702c-4b5a-86ab-f0c2f93f3873",
    "_uuid": "b092eca650105d8fe8b15f85fbe2747003b4f170"
   },
   "source": [
    "It does look like there are some remaining inconsistencies: 'd. i khan' and 'd.i khan' should probably be the same. (I [looked it up](https://en.wikipedia.org/wiki/List_of_most_populous_cities_in_Pakistan) and 'd.g khan' is a seperate city, so I shouldn't combine those.) \n",
    "\n",
    "I'm going to use the **[fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) (DEPRECATED**) (I, jgp-13, will use [thefuzz](https://github.com/seatgeek/thefuzz), an improved version of `fuzzywuzzy`) will use package to help identify which string are closest to each other. This dataset is small enough that we could probably could correct errors by hand, but that approach doesn't scale well. (Would you want to correct a thousand errors by hand? What about ten thousand? Automating things as early as possible is generally a good idea. Plus, it’s fun! :)\n",
    "\n",
    "> **Fuzzy matching:** The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n",
    "\n",
    "Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of cities that have the closest distance to \"d.i khan\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4fdcd726-4a4f-4348-b745-1e42c3338100",
    "_uuid": "a53c6f011f5c9144e9a48f329d5cf15e2feddec8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d. i khan', 100),\n",
       " ('d.i khan', 100),\n",
       " ('d.g khan', 88),\n",
       " ('khanewal', 50),\n",
       " ('sudhanoti', 47),\n",
       " ('hangu', 46),\n",
       " ('kohat', 46),\n",
       " ('dara adam khel', 45),\n",
       " ('chaman', 43),\n",
       " ('mardan', 43)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 closest matches to \"d.i khan\"\n",
    "matches = thefuzz.process.extract(\"d.i khan\", cities, limit=10, scorer=thefuzz.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68060fa2-b344-4e2a-b7ce-ca2b6233a4bc",
    "_uuid": "8ae2f8f1601f37b3bdce74fcb4a9817b41c10bf8"
   },
   "source": [
    "We can see that two of the items in the cities are very close to \"d.i khan\": \"d. i khan\" and \"d.i khan\". We can also see the \"d.g khan\", which is a seperate city, has a ratio of 88. Since we don't want to replace \"d.g khan\" with \"d.i khan\", let's replace all rows in our City column that have a ratio of > 90 with \"d. i khan\". \n",
    "\n",
    "To do this, I'm going to write a function. (It's a good idea to write a general purpose function you can reuse if you think you might have to do a specific task more than once or twice. This keeps you from having to copy and paste code too often, which saves time and can help prevent mistakes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "fb2068ed-9f09-47f4-b0e0-7fb97abda373",
    "_uuid": "ba5ad95702b3aa9f30788aa571d0c61f4e8131cc"
   },
   "outputs": [],
   "source": [
    "# function to replace rows in the provided column of the provided dataframe\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 10 closest matches to our input string\n",
    "    matches = thefuzz.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=thefuzz.fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a ratio > min_ratio (default = 90)\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # let us know the function's done\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "35635fb1-1456-4d40-b740-79e0c34f9b60",
    "_uuid": "33afd31ad4f34445fea3fb815b5b92f5c60f8a3e"
   },
   "source": [
    "Now that we have a function, we can put it to the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "23fd3ac0-f236-45c8-85cb-fad3706b2850",
    "_uuid": "6bcfc2b8f35d07b6c284767789b22974cc05ae18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# use the function we just wrote to replace close matches to \"d.i khan\" with \"d.i khan\"\n",
    "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e9c88b1c-a60d-4b0b-9d78-b305dd37dc45",
    "_uuid": "ae329ead1c242bcfe658d62320b57f3f7c6a715f"
   },
   "source": [
    "And now let's can check the unique values in our City column again and make sure we've tidied up d.i khan correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "730dc89a-30c6-4848-8fe0-a28e259ea427",
    "_uuid": "a8b54015e53fc9d7829266ca5839d6feb920d036"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n",
       "       'chaman', 'charsadda', 'd.g khan', 'd.i khan', 'dara adam khel',\n",
       "       'fateh jang', 'ghallanai, mohmand agency', 'gujrat', 'hangu',\n",
       "       'haripur', 'hayatabad', 'islamabad', 'jacobabad', 'karachi',\n",
       "       'karak', 'khanewal', 'khuzdar', 'khyber agency', 'kohat',\n",
       "       'kuram agency', 'kurram agency', 'lahore', 'lakki marwat',\n",
       "       'lasbela', 'lower dir', 'malakand', 'mansehra', 'mardan',\n",
       "       'mohmand agency', 'mosal kor, mohmand agency', 'multan',\n",
       "       'muzaffarabad', 'north waziristan', 'nowshehra', 'orakzai agency',\n",
       "       'peshawar', 'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n",
       "       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n",
       "       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n",
       "       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n",
       "       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'City' column\n",
    "cities = suicide_attacks['City'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5227b710-77f0-4cdb-92ce-fedadaa1a6e6",
    "_uuid": "f0b73ae1e4592e0da21788abebbb0f1a84c5eb7a"
   },
   "source": [
    "Excellent! Now we only have \"d.i khan\" in our dataframe and we didn't have to change anything by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! It looks like 'Kuram Agency' and 'Kurram Agency' should\n",
    "# be the same city. Correct the dataframe so that they are.\n",
    "# After verifying online, 'Kurram Agency' is the correct name, and 'Kuram Agency' is a misspelling.\n",
    "\n",
    "# Note: TheFuzz library has already been imported earlier.\n",
    "import thefuzz \n",
    "from thefuzz import process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n",
       "       'chaman', 'charsadda', 'd.g khan', 'd.i khan', 'dara adam khel',\n",
       "       'fateh jang', 'ghallanai, mohmand agency', 'gujrat', 'hangu',\n",
       "       'haripur', 'hayatabad', 'islamabad', 'jacobabad', 'karachi',\n",
       "       'karak', 'khanewal', 'khuzdar', 'khyber agency', 'kohat',\n",
       "       'kuram agency', 'kurram agency', 'lahore', 'lakki marwat',\n",
       "       'lasbela', 'lower dir', 'malakand', 'mansehra', 'mardan',\n",
       "       'mohmand agency', 'mosal kor, mohmand agency', 'multan',\n",
       "       'muzaffarabad', 'north waziristan', 'nowshehra', 'orakzai agency',\n",
       "       'peshawar', 'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n",
       "       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n",
       "       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n",
       "       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n",
       "       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'province' column\n",
    "cities = suicide_attacks['City'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kurram agency', 100),\n",
       " ('kuram agency', 96),\n",
       " ('bajaur agency', 69),\n",
       " ('khyber agency', 69),\n",
       " ('orakzai agency', 67),\n",
       " ('mosal kor, mohmand agency', 59),\n",
       " ('mohmand agency', 59),\n",
       " ('ghallanai, mohmand agency', 49),\n",
       " ('gujrat', 42),\n",
       " ('d.g khan', 38)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = process.extract('kurram agency', cities, \n",
    "                                         limit=10, scorer=thefuzz.fuzz.token_sort_ratio)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kurram agency', 'kuram agency']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only get matches with a ratio > 95\n",
    "close_matches = [matches[0] for matches in matches if matches[1] >= 95]\n",
    "close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>Saturday-August 4-2007</td>\n",
       "      <td>21 Rajab 1428 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:30am</td>\n",
       "      <td>kuram agency</td>\n",
       "      <td>32.9746</td>\n",
       "      <td>70.1456</td>\n",
       "      <td>fata</td>\n",
       "      <td>...</td>\n",
       "      <td>Sunni</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.Agency Headqurters \\nHospital</td>\n",
       "      <td>25.835</td>\n",
       "      <td>78.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>Saturday-February 16-2008</td>\n",
       "      <td>9 safar 1429 A.H.</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>evening</td>\n",
       "      <td>kuram agency</td>\n",
       "      <td>35.2227</td>\n",
       "      <td>72.4258</td>\n",
       "      <td>fata</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agency headquarter hospital</td>\n",
       "      <td>12.725</td>\n",
       "      <td>54.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>Friday-February 17-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:00 PM</td>\n",
       "      <td>kuram agency</td>\n",
       "      <td>32.9746</td>\n",
       "      <td>70.1456</td>\n",
       "      <td>fata</td>\n",
       "      <td>...</td>\n",
       "      <td>Shiite</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agency Headquarter Hospital</td>\n",
       "      <td>0.040</td>\n",
       "      <td>32.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>356</td>\n",
       "      <td>Monday-September 10-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:40pm</td>\n",
       "      <td>kuram agency</td>\n",
       "      <td>32.9746</td>\n",
       "      <td>70.1456</td>\n",
       "      <td>fata</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.935</td>\n",
       "      <td>67.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>Friday-July 26-2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evening</td>\n",
       "      <td>kuram agency</td>\n",
       "      <td>32.9746</td>\n",
       "      <td>70.1456</td>\n",
       "      <td>kpk</td>\n",
       "      <td>...</td>\n",
       "      <td>Shiite</td>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parachinar Headquarters Hospital</td>\n",
       "      <td>26.015</td>\n",
       "      <td>78.827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S#                       Date       Islamic Date Blast Day Type  \\\n",
       "53    54     Saturday-August 4-2007  21 Rajab 1428 A.H    Working Day   \n",
       "94    95  Saturday-February 16-2008  9 safar 1429 A.H.    Working Day   \n",
       "341  342    Friday-February 17-2012                NaN    Working Day   \n",
       "355  356   Monday-September 10-2012                NaN    Working Day   \n",
       "396  397        Friday-July 26-2013                NaN    Working Day   \n",
       "\n",
       "    Holiday Type     Time          City  Latitude Longitude Province  ...  \\\n",
       "53           NaN  10:30am  kuram agency   32.9746   70.1456     fata  ...   \n",
       "94           NaN  evening  kuram agency   35.2227   72.4258     fata  ...   \n",
       "341          NaN  2:00 PM  kuram agency   32.9746   70.1456     fata  ...   \n",
       "355          NaN   2:40pm  kuram agency   32.9746   70.1456     fata  ...   \n",
       "396          NaN  Evening  kuram agency   32.9746   70.1456      kpk  ...   \n",
       "\n",
       "    Targeted Sect if any Killed Min Killed Max Injured Min Injured Max  \\\n",
       "53                 Sunni        9.0       23.0        35.0          43   \n",
       "94                   NaN       38.0       47.0       109.0         110   \n",
       "341               Shiite       21.0       28.0         NaN          36   \n",
       "355                  NaN       14.0       15.0        40.0          80   \n",
       "396               Shiite       43.0       50.0       180.0         200   \n",
       "\n",
       "    No. of Suicide Blasts Explosive Weight (max)  \\\n",
       "53                    1.0                    NaN   \n",
       "94                    1.0                    NaN   \n",
       "341                   1.0                    NaN   \n",
       "355                   1.0                    NaN   \n",
       "396                   2.0                    NaN   \n",
       "\n",
       "                       Hospital Names  Temperature(C)  Temperature(F)  \n",
       "53   1.Agency Headqurters \\nHospital           25.835          78.503  \n",
       "94        Agency headquarter hospital          12.725          54.905  \n",
       "341       Agency Headquarter Hospital           0.040          32.072  \n",
       "355                               NaN          19.935          67.883  \n",
       "396  Parachinar Headquarters Hospital          26.015          78.827  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the rows of all the close matches in our dataframe\n",
    "rows_with_matches = suicide_attacks['City'].isin(close_matches)\n",
    "suicide_attacks[suicide_attacks['City']=='kuram agency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [S#, Date, Islamic Date, Blast Day Type, Holiday Type, Time, City, Latitude, Longitude, Province, Location, Location Category, Location Sensitivity, Open/Closed Space, Influencing Event/Event, Target Type, Targeted Sect if any, Killed Min, Killed Max, Injured Min, Injured Max, No. of Suicide Blasts, Explosive Weight (max), Hospital Names, Temperature(C), Temperature(F)]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all rows with close matches with the input matches \n",
    "suicide_attacks.loc[rows_with_matches, 'City'] = 'kurram agency'\n",
    "\n",
    "suicide_attacks[suicide_attacks['City']=='kuram agency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n",
    "\n",
    "Remember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also lets you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "## More practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "Do any other columns in this dataframe have inconsistent data entry? If you can find any, try to tidy them up.\n",
    "\n",
    "You can also try reading in the `PakistanSuicideAttacks Ver 6 (10-October-2017).csv` file from this dataset and tidying up any inconsistent columns in that data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Windows-1252'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psa_file_v6 = os.path.join(RAW_DATA_DIR, 'PakistanSuicideAttacks Ver 6 (10-October-2017).csv')\n",
    "with open(psa_file_v6, 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(20000))\n",
    "result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 492 entries, 0 to 491\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   S#                       492 non-null    int64  \n",
      " 1   Date                     492 non-null    object \n",
      " 2   Islamic Date             336 non-null    object \n",
      " 3   Blast Day Type           481 non-null    object \n",
      " 4   Holiday Type             72 non-null     object \n",
      " 5   Time                     281 non-null    object \n",
      " 6   City                     492 non-null    object \n",
      " 7   Latitude                 490 non-null    float64\n",
      " 8   Longitude                490 non-null    object \n",
      " 9   Province                 492 non-null    object \n",
      " 10  Location                 489 non-null    object \n",
      " 11  Location Category        457 non-null    object \n",
      " 12  Location Sensitivity     456 non-null    object \n",
      " 13  Open/Closed Space        457 non-null    object \n",
      " 14  Influencing Event/Event  187 non-null    object \n",
      " 15  Target Type              466 non-null    object \n",
      " 16  Targeted Sect if any     97 non-null     object \n",
      " 17  Killed Min               346 non-null    float64\n",
      " 18  Killed Max               476 non-null    float64\n",
      " 19  Injured Min              361 non-null    float64\n",
      " 20  Injured Max              460 non-null    object \n",
      " 21  No. of Suicide Blasts    410 non-null    float64\n",
      " 22  Explosive Weight (max)   169 non-null    object \n",
      " 23  Hospital Names           294 non-null    object \n",
      " 24  Temperature(C)           487 non-null    float64\n",
      " 25  Temperature(F)           485 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(18)\n",
      "memory usage: 100.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(psa_file_v6, encoding = result['encoding'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>476.00000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>32.621874</td>\n",
       "      <td>14.855491</td>\n",
       "      <td>15.30042</td>\n",
       "      <td>31.601108</td>\n",
       "      <td>1.117073</td>\n",
       "      <td>21.075554</td>\n",
       "      <td>69.906373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>142.172431</td>\n",
       "      <td>2.477845</td>\n",
       "      <td>17.659154</td>\n",
       "      <td>20.32867</td>\n",
       "      <td>38.762832</td>\n",
       "      <td>0.396749</td>\n",
       "      <td>8.390859</td>\n",
       "      <td>15.108953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.879503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.370000</td>\n",
       "      <td>27.734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>123.750000</td>\n",
       "      <td>31.823800</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.617500</td>\n",
       "      <td>58.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>33.583300</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.295000</td>\n",
       "      <td>70.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>369.250000</td>\n",
       "      <td>34.004300</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.115000</td>\n",
       "      <td>82.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>35.383300</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               S#    Latitude  Killed Min  Killed Max  Injured Min  \\\n",
       "count  492.000000  490.000000  346.000000   476.00000   361.000000   \n",
       "mean   246.500000   32.621874   14.855491    15.30042    31.601108   \n",
       "std    142.172431    2.477845   17.659154    20.32867    38.762832   \n",
       "min      1.000000   24.879503    0.000000     0.00000     0.000000   \n",
       "25%    123.750000   31.823800    3.000000     3.00000     7.000000   \n",
       "50%    246.500000   33.583300    8.000000     8.00000    20.000000   \n",
       "75%    369.250000   34.004300   20.750000    19.00000    40.000000   \n",
       "max    492.000000   35.383300  125.000000   148.00000   320.000000   \n",
       "\n",
       "       No. of Suicide Blasts  Temperature(C)  Temperature(F)  \n",
       "count             410.000000      487.000000      485.000000  \n",
       "mean                1.117073       21.075554       69.906373  \n",
       "std                 0.396749        8.390859       15.108953  \n",
       "min                 1.000000       -2.370000       27.734000  \n",
       "25%                 1.000000       14.617500       58.253000  \n",
       "50%                 1.000000       21.295000       70.331000  \n",
       "75%                 1.000000       28.115000       82.499000  \n",
       "max                 4.000000       44.000000      111.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Category</th>\n",
       "      <th>Location Sensitivity</th>\n",
       "      <th>Open/Closed Space</th>\n",
       "      <th>Influencing Event/Event</th>\n",
       "      <th>Target Type</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492</td>\n",
       "      <td>336</td>\n",
       "      <td>481</td>\n",
       "      <td>72</td>\n",
       "      <td>281</td>\n",
       "      <td>492</td>\n",
       "      <td>490</td>\n",
       "      <td>492</td>\n",
       "      <td>489</td>\n",
       "      <td>457</td>\n",
       "      <td>456</td>\n",
       "      <td>457</td>\n",
       "      <td>187</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>460</td>\n",
       "      <td>169</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>451</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>216</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>483</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Thursday-July 19-2007</td>\n",
       "      <td>5 Rajab 1428 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Peshawar</td>\n",
       "      <td>71.5448</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Imambargah</td>\n",
       "      <td>Police</td>\n",
       "      <td>High</td>\n",
       "      <td>Open</td>\n",
       "      <td>Sectarian strife</td>\n",
       "      <td>Military</td>\n",
       "      <td>Shiite</td>\n",
       "      <td>2</td>\n",
       "      <td>6kg</td>\n",
       "      <td>Lady Reading Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>398</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>264</td>\n",
       "      <td>317</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date      Islamic Date Blast Day Type Holiday Type  \\\n",
       "count                     492               336            481           72   \n",
       "unique                    451               301              3           15   \n",
       "top     Thursday-July 19-2007  5 Rajab 1428 A.H    Working Day      Weekend   \n",
       "freq                        3                 3            398           45   \n",
       "\n",
       "           Time      City Longitude Province    Location Location Category  \\\n",
       "count       281       492       490      492         489               457   \n",
       "unique      216        93        97        9         483                24   \n",
       "top     Evening  Peshawar   71.5448      KPK  Imambargah            Police   \n",
       "freq         12        71        71      250           3                90   \n",
       "\n",
       "       Location Sensitivity Open/Closed Space Influencing Event/Event  \\\n",
       "count                   456               457                     187   \n",
       "unique                    4                 6                     169   \n",
       "top                    High              Open        Sectarian strife   \n",
       "freq                    264               317                       7   \n",
       "\n",
       "       Target Type Targeted Sect if any Injured Max Explosive Weight (max)  \\\n",
       "count          466                   97         460                    169   \n",
       "unique          24                    7          91                    112   \n",
       "top       Military               Shiite           2                    6kg   \n",
       "freq           115                   38          20                      8   \n",
       "\n",
       "               Hospital Names  \n",
       "count                     294  \n",
       "unique                    236  \n",
       "top     Lady Reading Hospital  \n",
       "freq                       20  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include= ['category','object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from the Preliminary Analysis of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following an initial review of the dataset, the following adjustments and refinements are recommended:\n",
    "\n",
    "- The `'Date'` column should be converted to `datetime` format.\n",
    "- The `'Longitude'` column should be converted to `float` type.\n",
    "- There are two rows where both `'Latitude'` and `'Longitude'` contain null values. If a city and/or province is recorded, the geographical location can be researched and imputed accordingly.\n",
    "- The `'Injured Max'` column should be converted to a numeric type.\n",
    "- The following columns should be converted to `integer` type: `'Killed min'`, `'Killed max'`, `'Injured min'`, `'Injured max'`, and `'Suicide Blasts'`.\n",
    "- The `'Explosive Weight (max)'` column may require further analysis to ensure accuracy.\n",
    "- The suitability of converting temperatures from Celsius to Fahrenheit (`Temperature C to F`) should be assessed.\n",
    "- The `\"Open/Closed Space\"` column contains six unique values, whereas the expected number was only two or possibly three. This discrepancy suggests inconsistencies that require further investigation and standardisation.\n",
    "- Lists such as cities and provinces should be reviewed for consistency and correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising Date Formats and Correcting Misspellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell addresses inconsistencies in the `'Date'` column by performing the following steps:\n",
    "\n",
    "- Corrects a known misspelling in the dataset (`'Thursay' → 'Thursday'`).\n",
    "- Defines a list of expected date formats to ensure proper conversion.\n",
    "- Implements a function to iteratively attempt conversion using the predefined formats.\n",
    "- Applies the function to standardise all date entries.\n",
    "- Identifies any remaining entries that could not be converted, allowing for further investigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [S#, Date, Islamic Date, Blast Day Type, Holiday Type, Time, City, Latitude, Longitude, Province, Location, Location Category, Location Sensitivity, Open/Closed Space, Influencing Event/Event, Target Type, Targeted Sect if any, Killed Min, Killed Max, Injured Min, Injured Max, No. of Suicide Blasts, Explosive Weight (max), Hospital Names, Temperature(C), Temperature(F)]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix incorrect mispelled date value\n",
    "df.loc[452, 'Date'] = 'Thursday-Aug 27-2015'\n",
    "\n",
    "# List of possible date formats\n",
    "date_formats = [\n",
    "    '%A-%B %d-%Y',\n",
    "    '%A-%B-%d-%Y',\n",
    "    '%A-%b-%d-%Y',    \n",
    "    '%A-%b %d-%Y'     \n",
    "]\n",
    "\n",
    "# Function to convert dates by trying multiple formats\n",
    "def parse_dates(date):\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT  # Return NaT if no format matches\n",
    "\n",
    "# Convert and replace the 'Date' column\n",
    "df['Date'] = df['Date'].apply(parse_dates)\n",
    "\n",
    "# Check for any remaining NaT values\n",
    "df[df['Date'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Longitude to Float and Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell ensures the `'Longitude'` column is correctly formatted as a numeric type and addresses missing values in the dataset:\n",
    "\n",
    "- Converts the `'Longitude'` column to `float` for consistency in numerical operations.\n",
    "- Identifies and displays rows where `'Longitude'` values are missing.\n",
    "- Since both missing entries have corresponding `'City'` and `'Province'` values, their geographic coordinates are retrieved from **reliable sources**.\n",
    "- The missing latitude and longitude values are manually updated using coordinates from Wikipedia (last checked on **9th March 2025**):\n",
    "  - **Lahore, Punjab** → (`Latitude: 31.549722, Longitude: 74.343611`)\n",
    "  - **Quetta, Balochistan** → (`Latitude: 30.183333, Longitude: 67.000000`)\n",
    "- The corrected entries are displayed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.samaa.tv/pakistan/29-Jun-2015/shoot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S#       Date Islamic Date Blast Day Type Holiday Type Time    City  \\\n",
       "449  450 2015-06-29          NaN    Working Day          NaN  NaN  Lahore   \n",
       "450  451 2015-07-17          NaN        Holiday          NaN  NaN  Quetta   \n",
       "\n",
       "     Latitude  Longitude     Province  ... Targeted Sect if any Killed Min  \\\n",
       "449       NaN        NaN       Punjab  ...                  NaN        1.0   \n",
       "450       NaN        NaN  Balochistan  ...                  NaN        1.0   \n",
       "\n",
       "    Killed Max Injured Min                                        Injured Max  \\\n",
       "449        4.0         NaN  http://www.samaa.tv/pakistan/29-Jun-2015/shoot...   \n",
       "450        1.0         NaN                                                NaN   \n",
       "\n",
       "    No. of Suicide Blasts Explosive Weight (max)  Hospital Names  \\\n",
       "449                   NaN                    NaN             NaN   \n",
       "450                   NaN                    NaN             NaN   \n",
       "\n",
       "     Temperature(C)  Temperature(F)  \n",
       "449             NaN             NaN  \n",
       "450             NaN             NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>31.549722</td>\n",
       "      <td>74.343611</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.samaa.tv/pakistan/29-Jun-2015/shoot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>30.183333</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S#       Date Islamic Date Blast Day Type Holiday Type Time    City  \\\n",
       "449  450 2015-06-29          NaN    Working Day          NaN  NaN  Lahore   \n",
       "450  451 2015-07-17          NaN        Holiday          NaN  NaN  Quetta   \n",
       "\n",
       "      Latitude  Longitude     Province  ... Targeted Sect if any Killed Min  \\\n",
       "449  31.549722  74.343611       Punjab  ...                  NaN        1.0   \n",
       "450  30.183333  67.000000  Balochistan  ...                  NaN        1.0   \n",
       "\n",
       "    Killed Max Injured Min                                        Injured Max  \\\n",
       "449        4.0         NaN  http://www.samaa.tv/pakistan/29-Jun-2015/shoot...   \n",
       "450        1.0         NaN                                                NaN   \n",
       "\n",
       "    No. of Suicide Blasts Explosive Weight (max)  Hospital Names  \\\n",
       "449                   NaN                    NaN             NaN   \n",
       "450                   NaN                    NaN             NaN   \n",
       "\n",
       "     Temperature(C)  Temperature(F)  \n",
       "449             NaN             NaN  \n",
       "450             NaN             NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets change the type of the Longitude columnt to float\n",
    "df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "# Then Lets check the positions where there are two empty values\n",
    "display(df[df['Longitude'].isna()])\n",
    "\n",
    "# As there is a City and Province for the two empty values lets get it from Internet (both last checked on 2025-03-09)\n",
    "# https://en.wikipedia.org/wiki/Lahore \n",
    "df.loc[449, ['Latitude','Longitude']]=[31.549722, 74.343611] \n",
    "# https://en.wikipedia.org/wiki/Quetta \n",
    "df.loc[450, ['Latitude','Longitude']]=[30.183333, 67.0] \n",
    "display(df.loc[[449,450],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting  `'Injured Max'` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell processes the `'Injured Max'` column to maintain numerical consistency:\n",
    "\n",
    "- Converts `'Injured Max'` to numeric values, handling non-numeric entries as `NaN`.\n",
    "- Fills missing values in `'Injured Max'` with the column’s median to preserve distribution integrity.\n",
    "- Ensures that `'Injured Max'` is at least equal to `'Injured Min'` by applying a row-wise maximum.\n",
    "\n",
    "This guarantees that the reported maximum injuries are never lower than the minimum injuries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Injured Max' and 'Injured Min' to numeric, converting non-numeric values to NaN\n",
    "df['Injured Max'] = pd.to_numeric(df['Injured Max'], errors='coerce')\n",
    "\n",
    "# Fill missing values in 'Injured Max' with the median\n",
    "df['Injured Max'] = df['Injured Max'].fillna(df['Injured Max'].median())\n",
    "\n",
    "# Ensure 'Injured Max' is at least equal to 'Injured Min'\n",
    "df['Injured Max'] = df[['Injured Max', 'Injured Min']].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Standardising the 'Open/Closed Space' Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell ensures consistency in the `'Open/Closed Space'` column by performing the following steps:\n",
    "\n",
    "- **Retrieves unique values** to identify inconsistencies in formatting.\n",
    "- **Standardises text formatting** by:\n",
    "  - Removing leading and trailing spaces.\n",
    "  - Converting all values to lowercase to ensure uniformity.\n",
    "- **Replaces ambiguous entries**:\n",
    "  - The category `'open/closed'` is converted to `NaN` to reflect missing or unclear data.\n",
    "- **Displays the updated value counts**, including `NaN` values, to verify the cleaning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Closed', 'Open', 'open', 'Open ', nan, 'closed', 'Open/Closed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Open/Closed Space\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open/Closed Space\n",
       "open      329\n",
       "closed    127\n",
       "NaN        36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Open/Closed Space\"] = df[\"Open/Closed Space\"].str.strip().str.lower()\n",
    "df[\"Open/Closed Space\"] = df[\"Open/Closed Space\"].replace({\"open/closed\":np.nan})\n",
    "df[\"Open/Closed Space\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and Filling Missing Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step ensures consistency in temperature values by identifying and addressing missing data:\n",
    "\n",
    "- **Identifies rows where either `Temperature(C)` or `Temperature(F)` is missing** and displays them for review.\n",
    "- **Uses the conversion function `C2F()`** to fill missing Fahrenheit values where the corresponding Celsius value is available.\n",
    "- **Updates specific missing Fahrenheit values at index `475` and `490`**, ensuring accuracy while preserving the original dataset.\n",
    "- **Leaves rows where both temperature values are missing untouched**, as further work can be done to estimate these values using average temperatures for the corresponding zone.\n",
    "\n",
    "This approach ensures that temperature data remains complete where possible while highlighting areas that require additional imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C2F(celsius):\n",
    "    return (celsius * 9/5) + 32\n",
    "def F2C(fahrenheit):\n",
    "    return (fahrenheit - 32) * 5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Temperature(C)  Temperature(F)\n",
      "165             NaN             NaN\n",
      "449             NaN             NaN\n",
      "450             NaN             NaN\n",
      "473             NaN             NaN\n",
      "475            19.0             NaN\n",
      "479             NaN             NaN\n",
      "490            29.0             NaN\n"
     ]
    }
   ],
   "source": [
    "print(df[(df['Temperature(C)'].isna())| (df['Temperature(F)'].isna())][['Temperature(C)','Temperature(F)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[475, 'Temperature(F)'] = C2F(df.loc[475, 'Temperature(C)'])\n",
    "df.loc[490, 'Temperature(F)'] = C2F(df.loc[490, 'Temperature(C)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Cities and Provinces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardising City Names for Consistency\n",
    "\n",
    "This cell ensures that city names in the dataset are formatted uniformly by applying the following transformations:\n",
    "\n",
    "- **Converts all city names to lowercase** to maintain consistency and avoid case-sensitive mismatches.\n",
    "- **Removes any leading or trailing whitespace** to eliminate unintentional variations.\n",
    "- **Extracts all unique city names** from the dataset to identify inconsistencies.\n",
    "- **Sorts the unique city names alphabetically** to facilitate easier review and verification.\n",
    "\n",
    "These steps help standardise the data, making it easier to detect duplicates, match locations accurately, and perform further cleaning if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n",
       "       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n",
       "       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n",
       "       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n",
       "       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n",
       "       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n",
       "       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n",
       "       'mansehra', 'mardan', 'mohmand agency',\n",
       "       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n",
       "       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n",
       "       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n",
       "       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n",
       "       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n",
       "       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n",
       "       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to lower case\n",
    "df['City'] = df['City'].str.lower()\n",
    "# remove trailing white spaces\n",
    "df['City'] = df['City'].str.strip()\n",
    "\n",
    "# get all the unique values in the 'province' column\n",
    "cities = df['City'].unique()\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell ensures that city names are corrected and standardised by using fuzzy string matching to identify and replace similar variations. The process follows these steps:\n",
    "\n",
    "- **Defines a set of standard city names** (`d.i khan`, `kurram agency`, `mohmand agency`, `charsadda`) to be used as reference.\n",
    "- **Uses fuzzy matching (`thefuzz.process.extract`)** to find the closest matches for each standard name within the dataset.\n",
    "- **Filters matches with a similarity score of 90 or higher**, ensuring only highly similar names are considered.\n",
    "- **Replaces all identified variations with the corresponding standard name**, ensuring consistency in city names.\n",
    "\n",
    "By applying this approach, variations in spelling, formatting, or abbreviations are resolved, making the dataset more uniform and easier to analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.i khan: ['d.i khan', 'd. i khan']\n",
      "kurram agency: ['kurram agency', 'kuram agency']\n",
      "mohmand agency: ['mohmand agency', 'ghallanai, mohmand agency', 'mosal kor, mohmand agency']\n",
      "charsadda: ['charsadda', 'shabqadar-charsadda', 'tangi, charsadda district']\n"
     ]
    }
   ],
   "source": [
    "standard_names = [\"d.i khan\", \"kurram agency\", \"mohmand agency\", \"charsadda\"]\n",
    "\n",
    "for name in standard_names:\n",
    "    # Find the closest matches with a score of 90 or higher\n",
    "    matches = process.extract(name, cities, limit=5)\n",
    "    close_matches = [match[0] for match in matches if match[1] >= 90]\n",
    "    \n",
    "    print(f\"{name}: {close_matches}\")  # Display detected similar names\n",
    "    \n",
    "    # Replace all close matches with the standard name\n",
    "    df.loc[df['City'].isin(close_matches), 'City'] = name\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardising Province Names\n",
    "\n",
    "A similar procedure is applied to ensure consistency in province names within the dataset. This involves:\n",
    "\n",
    "- **Converting all names to lowercase** and **removing trailing spaces** to eliminate formatting inconsistencies.\n",
    "- **Identifying and replacing variations** (e.g., alternate spellings) to align with a standard set of province names.\n",
    "- **Ensuring uniformity** across the dataset, making it more reliable for analysis.\n",
    "\n",
    "This process helps prevent mismatches and inconsistencies that could affect grouping, filtering, and interpretation of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ajk', 'balochistan', 'baluchistan', 'capital', 'fata', 'kpk',\n",
       "       'punjab', 'sindh'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to lower case\n",
    "df['Province'] = df['Province'].str.lower()\n",
    "# remove trailing white spaces\n",
    "df['Province'] = df['Province'].str.strip()\n",
    "\n",
    "# get all the unique values in the 'province' column\n",
    "provinces = df['Province'].unique()\n",
    "# sort them alphabetically and then take a closer look\n",
    "provinces.sort()\n",
    "provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Province\"] = df[\"Province\"].replace({\"baluchistan\": \"balochistan\", 'capital':'ict', 'fata':'kpk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ict' 'sindh' 'balochistan' 'punjab' 'kpk' 'ajk']\n"
     ]
    }
   ],
   "source": [
    "print(df['Province'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['islamabad' 'karachi' 'quetta' 'rawalpindi' 'north waziristan' 'kohat'\n",
      " 'attock' 'sialkot' 'lahore' 'swat' 'hangu' 'bannu' 'lasbela' 'malakand'\n",
      " 'peshawar' 'd.i khan' 'lakki marwat' 'tank' 'gujrat' 'charsadda'\n",
      " 'kurram agency' 'shangla' 'bajaur agency' 'south waziristan' 'haripur'\n",
      " 'sargodha' 'nowshehra' 'mohmand agency' 'dara adam khel' 'khyber agency'\n",
      " 'mardan' 'bhakkar' 'orakzai agency' 'buner' 'd.g khan' 'pishin' 'chakwal'\n",
      " 'upper dir' 'muzaffarabad' 'totalai' 'multan' 'lower dir' 'sudhanoti'\n",
      " 'poonch' 'mansehra' 'karak' 'swabi' 'shikarpur' 'sukkur' 'chaman'\n",
      " 'khanewal' 'fateh jang' 'taftan' 'tirah valley' 'wagah' 'zhob' 'taunsa'\n",
      " 'jacobabad' 'khuzdar' 'hayatabad' 'sehwan town']\n"
     ]
    }
   ],
   "source": [
    "print(df['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakistan_csv_file=os.path.join(CLEAN_DATA_DIR, 'pakistan_clean.csv')\n",
    "df.to_csv(pakistan_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Analysis Base)",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

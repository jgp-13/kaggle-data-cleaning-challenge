{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Challenge - Optional cleaning (Taken from nb5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "## INTRO (Text taken from the `More Practice!` section of the nb5)\n",
    "\n",
    "Do any other columns in this dataframe have inconsistent data entry? If you can find any, try to tidy them up.\n",
    "\n",
    "You can also try reading in the `PakistanSuicideAttacks Ver 6 (10-October-2017).csv` file from this dataset and tidying up any inconsistent columns in that data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the necessary libraries required for this analysis. The datasets will be introduced later in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
    "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f"
   },
   "outputs": [],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpful modules\n",
    "import thefuzz\n",
    "from thefuzz import process\n",
    "import chardet\n",
    "\n",
    "# Handling directories\n",
    "import os\n",
    "import kaggle_cleaning\n",
    "from kaggle_cleaning.config import RAW_DATA_DIR, CLEAN_DATA_DIR\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attempting to read the `'PakistanSuicideAttacks Ver 6 (10-October-2017).csv'` file for the first time, a character encoding error occurred. To resolve this, I will first determine the correct encoding before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Windows-1252'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psa_file_v6 = os.path.join(RAW_DATA_DIR, 'PakistanSuicideAttacks Ver 6 (10-October-2017).csv')\n",
    "with open(psa_file_v6, 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(20000))\n",
    "result['encoding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 'Windows-1252' encoding, I will now read the CSV file and store it as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(psa_file_v6, encoding = result['encoding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Examination  \n",
    "\n",
    "To assess the structure and quality of the dataset, an initial examination is carried out. This helps identify missing values, data types, and potential inconsistencies in the records. Additionally, a statistical summary provides insight into the distribution of numerical variables, allowing for the detection of anomalies that may require further attention.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 492 entries, 0 to 491\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   S#                       492 non-null    int64  \n",
      " 1   Date                     492 non-null    object \n",
      " 2   Islamic Date             336 non-null    object \n",
      " 3   Blast Day Type           481 non-null    object \n",
      " 4   Holiday Type             72 non-null     object \n",
      " 5   Time                     281 non-null    object \n",
      " 6   City                     492 non-null    object \n",
      " 7   Latitude                 490 non-null    float64\n",
      " 8   Longitude                490 non-null    object \n",
      " 9   Province                 492 non-null    object \n",
      " 10  Location                 489 non-null    object \n",
      " 11  Location Category        457 non-null    object \n",
      " 12  Location Sensitivity     456 non-null    object \n",
      " 13  Open/Closed Space        457 non-null    object \n",
      " 14  Influencing Event/Event  187 non-null    object \n",
      " 15  Target Type              466 non-null    object \n",
      " 16  Targeted Sect if any     97 non-null     object \n",
      " 17  Killed Min               346 non-null    float64\n",
      " 18  Killed Max               476 non-null    float64\n",
      " 19  Injured Min              361 non-null    float64\n",
      " 20  Injured Max              460 non-null    object \n",
      " 21  No. of Suicide Blasts    410 non-null    float64\n",
      " 22  Explosive Weight (max)   169 non-null    object \n",
      " 23  Hospital Names           294 non-null    object \n",
      " 24  Temperature(C)           487 non-null    float64\n",
      " 25  Temperature(F)           485 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(18)\n",
      "memory usage: 100.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>476.00000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>32.621874</td>\n",
       "      <td>14.855491</td>\n",
       "      <td>15.30042</td>\n",
       "      <td>31.601108</td>\n",
       "      <td>1.117073</td>\n",
       "      <td>21.075554</td>\n",
       "      <td>69.906373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>142.172431</td>\n",
       "      <td>2.477845</td>\n",
       "      <td>17.659154</td>\n",
       "      <td>20.32867</td>\n",
       "      <td>38.762832</td>\n",
       "      <td>0.396749</td>\n",
       "      <td>8.390859</td>\n",
       "      <td>15.108953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.879503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.370000</td>\n",
       "      <td>27.734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>123.750000</td>\n",
       "      <td>31.823800</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.617500</td>\n",
       "      <td>58.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>33.583300</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.295000</td>\n",
       "      <td>70.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>369.250000</td>\n",
       "      <td>34.004300</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.115000</td>\n",
       "      <td>82.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>35.383300</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               S#    Latitude  Killed Min  Killed Max  Injured Min  \\\n",
       "count  492.000000  490.000000  346.000000   476.00000   361.000000   \n",
       "mean   246.500000   32.621874   14.855491    15.30042    31.601108   \n",
       "std    142.172431    2.477845   17.659154    20.32867    38.762832   \n",
       "min      1.000000   24.879503    0.000000     0.00000     0.000000   \n",
       "25%    123.750000   31.823800    3.000000     3.00000     7.000000   \n",
       "50%    246.500000   33.583300    8.000000     8.00000    20.000000   \n",
       "75%    369.250000   34.004300   20.750000    19.00000    40.000000   \n",
       "max    492.000000   35.383300  125.000000   148.00000   320.000000   \n",
       "\n",
       "       No. of Suicide Blasts  Temperature(C)  Temperature(F)  \n",
       "count             410.000000      487.000000      485.000000  \n",
       "mean                1.117073       21.075554       69.906373  \n",
       "std                 0.396749        8.390859       15.108953  \n",
       "min                 1.000000       -2.370000       27.734000  \n",
       "25%                 1.000000       14.617500       58.253000  \n",
       "50%                 1.000000       21.295000       70.331000  \n",
       "75%                 1.000000       28.115000       82.499000  \n",
       "max                 4.000000       44.000000      111.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Category</th>\n",
       "      <th>Location Sensitivity</th>\n",
       "      <th>Open/Closed Space</th>\n",
       "      <th>Influencing Event/Event</th>\n",
       "      <th>Target Type</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492</td>\n",
       "      <td>336</td>\n",
       "      <td>481</td>\n",
       "      <td>72</td>\n",
       "      <td>281</td>\n",
       "      <td>492</td>\n",
       "      <td>490</td>\n",
       "      <td>492</td>\n",
       "      <td>489</td>\n",
       "      <td>457</td>\n",
       "      <td>456</td>\n",
       "      <td>457</td>\n",
       "      <td>187</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>460</td>\n",
       "      <td>169</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>451</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>216</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>483</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Thursday-July 19-2007</td>\n",
       "      <td>5 Rajab 1428 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Peshawar</td>\n",
       "      <td>71.5448</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Imambargah</td>\n",
       "      <td>Police</td>\n",
       "      <td>High</td>\n",
       "      <td>Open</td>\n",
       "      <td>Sectarian strife</td>\n",
       "      <td>Military</td>\n",
       "      <td>Shiite</td>\n",
       "      <td>2</td>\n",
       "      <td>6kg</td>\n",
       "      <td>Lady Reading Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>398</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>264</td>\n",
       "      <td>317</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date      Islamic Date Blast Day Type Holiday Type  \\\n",
       "count                     492               336            481           72   \n",
       "unique                    451               301              3           15   \n",
       "top     Thursday-July 19-2007  5 Rajab 1428 A.H    Working Day      Weekend   \n",
       "freq                        3                 3            398           45   \n",
       "\n",
       "           Time      City Longitude Province    Location Location Category  \\\n",
       "count       281       492       490      492         489               457   \n",
       "unique      216        93        97        9         483                24   \n",
       "top     Evening  Peshawar   71.5448      KPK  Imambargah            Police   \n",
       "freq         12        71        71      250           3                90   \n",
       "\n",
       "       Location Sensitivity Open/Closed Space Influencing Event/Event  \\\n",
       "count                   456               457                     187   \n",
       "unique                    4                 6                     169   \n",
       "top                    High              Open        Sectarian strife   \n",
       "freq                    264               317                       7   \n",
       "\n",
       "       Target Type Targeted Sect if any Injured Max Explosive Weight (max)  \\\n",
       "count          466                   97         460                    169   \n",
       "unique          24                    7          91                    112   \n",
       "top       Military               Shiite           2                    6kg   \n",
       "freq           115                   38          20                      8   \n",
       "\n",
       "               Hospital Names  \n",
       "count                     294  \n",
       "unique                    236  \n",
       "top     Lady Reading Hospital  \n",
       "freq                       20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include= ['category','object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations from the Preliminary Analysis of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following an initial review of the dataset, the following adjustments and refinements are recommended:\n",
    "\n",
    "- The `'Date'` column should be converted to `datetime` format.\n",
    "- The `'Longitude'` column should be converted to `float` type.\n",
    "- There are two rows where both `'Latitude'` and `'Longitude'` contain null values. If a city and/or province is recorded, the geographical location can be researched and imputed accordingly.\n",
    "- The `'Injured Max'` column should be converted to a numeric type.\n",
    "- The following columns should be converted to `integer` type: `'Killed min'`, `'Killed max'`, `'Injured min'`, `'Injured max'`, and `'Suicide Blasts'`.\n",
    "- The `'Explosive Weight (max)'` column may require further analysis to ensure accuracy.\n",
    "- The suitability of converting temperatures from Celsius to Fahrenheit (`Temperature C to F`) should be assessed.\n",
    "- The `\"Open/Closed Space\"` column contains six unique values, whereas the expected number was only two or possibly three. This discrepancy suggests inconsistencies that require further investigation and standardisation.\n",
    "- Lists such as cities and provinces should be reviewed for consistency and correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardising Date Formats and Correcting Misspellings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell addresses inconsistencies in the `'Date'` column by performing the following steps:\n",
    "\n",
    "- Corrects a known misspelling in the dataset (`'Thursay' → 'Thursday'`).\n",
    "- Defines a list of expected date formats to ensure proper conversion.\n",
    "- Implements a function to iteratively attempt conversion using the predefined formats.\n",
    "- Applies the function to standardise all date entries.\n",
    "- Identifies any remaining entries that could not be converted, allowing for further investigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [S#, Date, Islamic Date, Blast Day Type, Holiday Type, Time, City, Latitude, Longitude, Province, Location, Location Category, Location Sensitivity, Open/Closed Space, Influencing Event/Event, Target Type, Targeted Sect if any, Killed Min, Killed Max, Injured Min, Injured Max, No. of Suicide Blasts, Explosive Weight (max), Hospital Names, Temperature(C), Temperature(F)]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix incorrect mispelled date value\n",
    "df.loc[452, 'Date'] = 'Thursday-Aug 27-2015'\n",
    "\n",
    "# List of possible date formats\n",
    "date_formats = [\n",
    "    '%A-%B %d-%Y',\n",
    "    '%A-%B-%d-%Y',\n",
    "    '%A-%b-%d-%Y',    \n",
    "    '%A-%b %d-%Y'     \n",
    "]\n",
    "\n",
    "# Function to convert dates by trying multiple formats\n",
    "def parse_dates(date):\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT  # Return NaT if no format matches\n",
    "\n",
    "# Convert and replace the 'Date' column\n",
    "df['Date'] = df['Date'].apply(parse_dates)\n",
    "\n",
    "# Check for any remaining NaT values\n",
    "df[df['Date'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Longitude to Float and Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell ensures the `'Longitude'` column is correctly formatted as a numeric type and addresses missing values in the dataset:\n",
    "\n",
    "- Converts the `'Longitude'` column to `float` for consistency in numerical operations.\n",
    "- Identifies and displays rows where `'Longitude'` values are missing.\n",
    "- Since both missing entries have corresponding `'City'` and `'Province'` values, their geographic coordinates are retrieved from **reliable sources**.\n",
    "- The missing latitude and longitude values are manually updated using coordinates from Wikipedia (last checked on **9th March 2025**):\n",
    "  - **Lahore, Punjab** → (`Latitude: 31.549722, Longitude: 74.343611`)\n",
    "  - **Quetta, Balochistan** → (`Latitude: 30.183333, Longitude: 67.000000`)\n",
    "- The corrected entries are displayed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.samaa.tv/pakistan/29-Jun-2015/shoot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S#       Date Islamic Date Blast Day Type Holiday Type Time    City  \\\n",
       "449  450 2015-06-29          NaN    Working Day          NaN  NaN  Lahore   \n",
       "450  451 2015-07-17          NaN        Holiday          NaN  NaN  Quetta   \n",
       "\n",
       "     Latitude  Longitude     Province  ... Targeted Sect if any Killed Min  \\\n",
       "449       NaN        NaN       Punjab  ...                  NaN        1.0   \n",
       "450       NaN        NaN  Balochistan  ...                  NaN        1.0   \n",
       "\n",
       "    Killed Max Injured Min                                        Injured Max  \\\n",
       "449        4.0         NaN  http://www.samaa.tv/pakistan/29-Jun-2015/shoot...   \n",
       "450        1.0         NaN                                                NaN   \n",
       "\n",
       "    No. of Suicide Blasts Explosive Weight (max)  Hospital Names  \\\n",
       "449                   NaN                    NaN             NaN   \n",
       "450                   NaN                    NaN             NaN   \n",
       "\n",
       "     Temperature(C)  Temperature(F)  \n",
       "449             NaN             NaN  \n",
       "450             NaN             NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S#</th>\n",
       "      <th>Date</th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Province</th>\n",
       "      <th>...</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Killed Min</th>\n",
       "      <th>Killed Max</th>\n",
       "      <th>Injured Min</th>\n",
       "      <th>Injured Max</th>\n",
       "      <th>No. of Suicide Blasts</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>31.549722</td>\n",
       "      <td>74.343611</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.samaa.tv/pakistan/29-Jun-2015/shoot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>30.183333</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S#       Date Islamic Date Blast Day Type Holiday Type Time    City  \\\n",
       "449  450 2015-06-29          NaN    Working Day          NaN  NaN  Lahore   \n",
       "450  451 2015-07-17          NaN        Holiday          NaN  NaN  Quetta   \n",
       "\n",
       "      Latitude  Longitude     Province  ... Targeted Sect if any Killed Min  \\\n",
       "449  31.549722  74.343611       Punjab  ...                  NaN        1.0   \n",
       "450  30.183333  67.000000  Balochistan  ...                  NaN        1.0   \n",
       "\n",
       "    Killed Max Injured Min                                        Injured Max  \\\n",
       "449        4.0         NaN  http://www.samaa.tv/pakistan/29-Jun-2015/shoot...   \n",
       "450        1.0         NaN                                                NaN   \n",
       "\n",
       "    No. of Suicide Blasts Explosive Weight (max)  Hospital Names  \\\n",
       "449                   NaN                    NaN             NaN   \n",
       "450                   NaN                    NaN             NaN   \n",
       "\n",
       "     Temperature(C)  Temperature(F)  \n",
       "449             NaN             NaN  \n",
       "450             NaN             NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets change the type of the Longitude columnt to float\n",
    "df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "# Then Lets check the positions where there are two empty values\n",
    "display(df[df['Longitude'].isna()])\n",
    "\n",
    "# As there is a City and Province for the two empty values lets get it from Internet (both last checked on 2025-03-09)\n",
    "# https://en.wikipedia.org/wiki/Lahore \n",
    "df.loc[449, ['Latitude','Longitude']]=[31.549722, 74.343611] \n",
    "# https://en.wikipedia.org/wiki/Quetta \n",
    "df.loc[450, ['Latitude','Longitude']]=[30.183333, 67.0] \n",
    "display(df.loc[[449,450],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting  `'Injured Max'` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell processes the `'Injured Max'` column to maintain numerical consistency:\n",
    "\n",
    "- Converts `'Injured Max'` to numeric values, handling non-numeric entries as `NaN`.\n",
    "- Fills missing values in `'Injured Max'` with the column’s median to preserve distribution integrity.\n",
    "- Ensures that `'Injured Max'` is at least equal to `'Injured Min'` by applying a row-wise maximum.\n",
    "\n",
    "This guarantees that the reported maximum injuries are never lower than the minimum injuries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Injured Max' and 'Injured Min' to numeric, converting non-numeric values to NaN\n",
    "df['Injured Max'] = pd.to_numeric(df['Injured Max'], errors='coerce')\n",
    "\n",
    "# Fill missing values in 'Injured Max' with the median\n",
    "df['Injured Max'] = df['Injured Max'].fillna(df['Injured Max'].median())\n",
    "\n",
    "# Ensure 'Injured Max' is at least equal to 'Injured Min'\n",
    "df['Injured Max'] = df[['Injured Max', 'Injured Min']].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Standardising the 'Open/Closed Space' Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell ensures consistency in the `'Open/Closed Space'` column by performing the following steps:\n",
    "\n",
    "- **Retrieves unique values** to identify inconsistencies in formatting.\n",
    "- **Standardises text formatting** by:\n",
    "  - Removing leading and trailing spaces.\n",
    "  - Converting all values to lowercase to ensure uniformity.\n",
    "- **Replaces ambiguous entries**:\n",
    "  - The category `'open/closed'` is converted to `NaN` to reflect missing or unclear data.\n",
    "- **Displays the updated value counts**, including `NaN` values, to verify the cleaning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Closed', 'Open', 'open', 'Open ', nan, 'closed', 'Open/Closed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Open/Closed Space\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open/Closed Space\n",
       "open      329\n",
       "closed    127\n",
       "NaN        36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Open/Closed Space\"] = df[\"Open/Closed Space\"].str.strip().str.lower()\n",
    "df[\"Open/Closed Space\"] = df[\"Open/Closed Space\"].replace({\"open/closed\":np.nan})\n",
    "df[\"Open/Closed Space\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and Filling Missing Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step ensures consistency in temperature values by identifying and addressing missing data:\n",
    "\n",
    "- **Identifies rows where either `Temperature(C)` or `Temperature(F)` is missing** and displays them for review.\n",
    "- **Uses the conversion function `C2F()`** to fill missing Fahrenheit values where the corresponding Celsius value is available.\n",
    "- **Updates specific missing Fahrenheit values at index `475` and `490`**, ensuring accuracy while preserving the original dataset.\n",
    "- **Leaves rows where both temperature values are missing untouched**, as further work can be done to estimate these values using average temperatures for the corresponding zone.\n",
    "\n",
    "This approach ensures that temperature data remains complete where possible while highlighting areas that require additional imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C2F(celsius):\n",
    "    return (celsius * 9/5) + 32\n",
    "def F2C(fahrenheit):\n",
    "    return (fahrenheit - 32) * 5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Temperature(C)  Temperature(F)\n",
      "165             NaN             NaN\n",
      "449             NaN             NaN\n",
      "450             NaN             NaN\n",
      "473             NaN             NaN\n",
      "475            19.0             NaN\n",
      "479             NaN             NaN\n",
      "490            29.0             NaN\n"
     ]
    }
   ],
   "source": [
    "print(df[(df['Temperature(C)'].isna())| (df['Temperature(F)'].isna())][['Temperature(C)','Temperature(F)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[475, 'Temperature(F)'] = C2F(df.loc[475, 'Temperature(C)'])\n",
    "df.loc[490, 'Temperature(F)'] = C2F(df.loc[490, 'Temperature(C)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Cities and Provinces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardising City Names for Consistency\n",
    "\n",
    "This cell ensures that city names in the dataset are formatted uniformly by applying the following transformations:\n",
    "\n",
    "- **Converts all city names to lowercase** to maintain consistency and avoid case-sensitive mismatches.\n",
    "- **Removes any leading or trailing whitespace** to eliminate unintentional variations.\n",
    "- **Extracts all unique city names** from the dataset to identify inconsistencies.\n",
    "- **Sorts the unique city names alphabetically** to facilitate easier review and verification.\n",
    "\n",
    "These steps help standardise the data, making it easier to detect duplicates, match locations accurately, and perform further cleaning if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n",
       "       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n",
       "       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n",
       "       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n",
       "       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n",
       "       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n",
       "       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n",
       "       'mansehra', 'mardan', 'mohmand agency',\n",
       "       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n",
       "       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n",
       "       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n",
       "       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n",
       "       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n",
       "       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n",
       "       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to lower case\n",
    "df['City'] = df['City'].str.lower()\n",
    "# remove trailing white spaces\n",
    "df['City'] = df['City'].str.strip()\n",
    "\n",
    "# get all the unique values in the 'province' column\n",
    "cities = df['City'].unique()\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell ensures that city names are corrected and standardised by using fuzzy string matching to identify and replace similar variations. The process follows these steps:\n",
    "\n",
    "- **Defines a set of standard city names** (`d.i khan`, `kurram agency`, `mohmand agency`, `charsadda`) to be used as reference.\n",
    "- **Uses fuzzy matching (`thefuzz.process.extract`)** to find the closest matches for each standard name within the dataset.\n",
    "- **Filters matches with a similarity score of 90 or higher**, ensuring only highly similar names are considered.\n",
    "- **Replaces all identified variations with the corresponding standard name**, ensuring consistency in city names.\n",
    "\n",
    "By applying this approach, variations in spelling, formatting, or abbreviations are resolved, making the dataset more uniform and easier to analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.i khan: ['d.i khan', 'd. i khan']\n",
      "kurram agency: ['kurram agency', 'kuram agency']\n",
      "mohmand agency: ['mohmand agency', 'ghallanai, mohmand agency', 'mosal kor, mohmand agency']\n",
      "charsadda: ['charsadda', 'shabqadar-charsadda', 'tangi, charsadda district']\n"
     ]
    }
   ],
   "source": [
    "standard_names = [\"d.i khan\", \"kurram agency\", \"mohmand agency\", \"charsadda\"]\n",
    "\n",
    "for name in standard_names:\n",
    "    # Find the closest matches with a score of 90 or higher\n",
    "    matches = process.extract(name, cities, limit=5)\n",
    "    close_matches = [match[0] for match in matches if match[1] >= 90]\n",
    "    \n",
    "    print(f\"{name}: {close_matches}\")  # Display detected similar names\n",
    "    \n",
    "    # Replace all close matches with the standard name\n",
    "    df.loc[df['City'].isin(close_matches), 'City'] = name\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardising Province Names\n",
    "\n",
    "A similar procedure is applied to ensure consistency in province names within the dataset. This involves:\n",
    "\n",
    "- **Converting all names to lowercase** and **removing trailing spaces** to eliminate formatting inconsistencies.\n",
    "- **Identifying and replacing variations** (e.g., alternate spellings) to align with a standard set of province names.\n",
    "- **Ensuring uniformity** across the dataset, making it more reliable for analysis.\n",
    "\n",
    "This process helps prevent mismatches and inconsistencies that could affect grouping, filtering, and interpretation of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ajk', 'balochistan', 'baluchistan', 'capital', 'fata', 'kpk',\n",
       "       'punjab', 'sindh'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to lower case\n",
    "df['Province'] = df['Province'].str.lower()\n",
    "# remove trailing white spaces\n",
    "df['Province'] = df['Province'].str.strip()\n",
    "\n",
    "# get all the unique values in the 'province' column\n",
    "provinces = df['Province'].unique()\n",
    "# sort them alphabetically and then take a closer look\n",
    "provinces.sort()\n",
    "provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Province\"] = df[\"Province\"].replace({\"baluchistan\": \"balochistan\", 'capital':'ict', 'fata':'kpk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ict' 'sindh' 'balochistan' 'punjab' 'kpk' 'ajk']\n"
     ]
    }
   ],
   "source": [
    "print(df['Province'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['islamabad' 'karachi' 'quetta' 'rawalpindi' 'north waziristan' 'kohat'\n",
      " 'attock' 'sialkot' 'lahore' 'swat' 'hangu' 'bannu' 'lasbela' 'malakand'\n",
      " 'peshawar' 'd.i khan' 'lakki marwat' 'tank' 'gujrat' 'charsadda'\n",
      " 'kurram agency' 'shangla' 'bajaur agency' 'south waziristan' 'haripur'\n",
      " 'sargodha' 'nowshehra' 'mohmand agency' 'dara adam khel' 'khyber agency'\n",
      " 'mardan' 'bhakkar' 'orakzai agency' 'buner' 'd.g khan' 'pishin' 'chakwal'\n",
      " 'upper dir' 'muzaffarabad' 'totalai' 'multan' 'lower dir' 'sudhanoti'\n",
      " 'poonch' 'mansehra' 'karak' 'swabi' 'shikarpur' 'sukkur' 'chaman'\n",
      " 'khanewal' 'fateh jang' 'taftan' 'tirah valley' 'wagah' 'zhob' 'taunsa'\n",
      " 'jacobabad' 'khuzdar' 'hayatabad' 'sehwan town']\n"
     ]
    }
   ],
   "source": [
    "print(df['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakistan_csv_file=os.path.join(CLEAN_DATA_DIR, 'pakistan_clean.csv')\n",
    "df.to_csv(pakistan_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Categorical Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistency and detect potential issues, each column containing textual or categorical data will be reviewed. This step helps identify irregularities such as inconsistent formatting, unexpected values, or missing entries that may require standardisation or correction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Blast Day Type'`: Validating and Correcting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistency in the dataset, the `\"Blast Day Type\"` column is reviewed and updated where necessary. If the value is missing, it is assigned based on the corresponding date. Rows marked as `\"Holiday\"` remain unchanged, while any incorrect classifications are corrected to either `\"Working Day\"` or `\"Weekend\"` in alignment with the actual day of the week.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Holiday', 'Working Day', nan, 'Weekend'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Blast Day Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine the correct Blast Day Type\n",
    "def correct_blast_day_type(row):\n",
    "    if pd.isna(row['Blast Day Type']):  # If 'Blast Day Type' is NaN, assign based on the date\n",
    "        return 'Weekend' if row['Date'].weekday() >= 5 else 'Working Day'\n",
    "    elif row['Blast Day Type'] == 'Holiday':  # If 'Blast Day Type' is 'Holiday', keep it unchanged\n",
    "        return 'Holiday'\n",
    "    else:  # Otherwise, validate and correct it\n",
    "        correct_type = 'Weekend' if row['Date'].weekday() >= 5 else 'Working Day'\n",
    "        return correct_type if row['Blast Day Type'] != correct_type else row['Blast Day Type']\n",
    "\n",
    "# Apply the function to correct the 'Blast Day Type' column\n",
    "df['Blast Day Type'] = df.apply(correct_blast_day_type, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Holiday Types'`: Standardising\n",
    "\n",
    "In order to maintain consistency across the dataset, a few changes are made to the `'Holiday Type'` column:\n",
    "- All instances of `'Weekend'` are reclassified as `'General Holiday'`.\n",
    "- The values `'Ashura'` and `'Ashura Holiday'` are merged into a single category, `'Ashura'`.\n",
    "- Variations of `'Christmas/ birthday of Quaid-e-Azam'` are standardised to a consistent spelling, `'Christmas/birthday of Quaid-e-Azam'`.\n",
    "\n",
    "These adjustments ensure that the holiday types are represented uniformly, making the data cleaner and more accurate for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Weekend', nan, 'Christmas/birthday of Quaid-e-Azam', 'Ashura',\n",
       "       'Eid Milad un-Nabi', 'Iqbal Day', 'Eid-ul-azha', 'Labour Day',\n",
       "       'Eid-ul-Fitar', 'Pakistan Day', 'Defence Day',\n",
       "       'Christmas/ birthday of Quaid-e-Azam', 'General Elections',\n",
       "       'Eid Holidays', 'Ashura Holiday', 'Eid ul Azha Holiday'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Holiday Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Weekend' with 'General Holiday'\n",
    "df['Holiday Type'] = df['Holiday Type'].replace('Weekend', 'General Holiday')\n",
    "# Merge 'Ashura' and 'Ashura Holiday'\n",
    "df['Holiday Type'] = df['Holiday Type'].replace({'Ashura Holiday': 'Ashura'})\n",
    "# Merge 'Christmas/birthday of Quaid-e-Azam' values\n",
    "df['Holiday Type'] = df['Holiday Type'].replace({\n",
    "    'Christmas/ birthday of Quaid-e-Azam': 'Christmas/birthday of Quaid-e-Azam'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Location'`: Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'Location'` column contains **484 unique values**. Given the high number of unique locations, it may not be practical to correct all of them manually. In such cases, it is important to assess whether standardisation or consolidation of values would significantly impact the analysis. If the column is not central to the project's objectives or if correcting the entries would introduce more complexity than it’s worth, we might choose to leave the column as it is, while still monitoring for any obvious inconsistencies or issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Location Category'`: Standardising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistency across the dataset, several changes are made to the `'Location Category'` column:\n",
    "- The values `'foreign'` and `'Foreign'` are standardised to `'Foreigner'`.\n",
    "- `'Government Official'` and `'Government/Office Building'` are merged into the broader category `'Government'`.\n",
    "- `'Residential Building'` and `'Residence'` are grouped under the category `'Residential'`.\n",
    "- `'Commercial/residence'` is standardised to `'Commercial'`.\n",
    "- The value `'Mobile'` is merged with `'Transport'`.\n",
    "- Blank spaces and the string `'nan'` are converted to `np.nan` to handle missing or invalid entries.\n",
    "\n",
    "These changes ensure that location categories are consistent, making the dataset more uniform and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Foreign', 'Office Building', 'Hotel', 'Religious', 'Mobile',\n",
       "       'Military', 'Residence', 'Park/Ground', 'Market', 'Police',\n",
       "       'Airport', 'Government', 'Transport', 'Hospital', 'Educational',\n",
       "       'Civilian', 'Bank', 'Foreigner', 'Government/Office Building',\n",
       "       'Government Official', 'foreign', nan, 'Residential Building',\n",
       "       'Commercial/residence', ' '], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location Category\n",
       "Police             90\n",
       "Transport          75\n",
       "Military           69\n",
       "Religious          57\n",
       "Market             40\n",
       "NaN                36\n",
       "Park/Ground        32\n",
       "Residential        25\n",
       "Government         21\n",
       "Hotel              10\n",
       "Office Building     9\n",
       "Foreigner           8\n",
       "Educational         6\n",
       "Hospital            5\n",
       "Bank                4\n",
       "Commercial          2\n",
       "Airport             1\n",
       "Civilian            1\n",
       "Residence           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardise values in 'Location Category' column\n",
    "df['Location Category'] = df['Location Category'].replace({\n",
    "    'foreign': 'Foreigner',  # Standardising case inconsistency\n",
    "    'Foreign': 'Foreigner',  # Standardising 'Foreign' to 'Foreigner'\n",
    "    'Government Official': 'Government',  # Grouping 'Government Official' with 'Government'\n",
    "    'Government/Office Building': 'Government',  # Grouping 'Government/Office Building' with 'Government'\n",
    "    'Residential Building': 'Residence',  # Grouping 'Residential Building' with 'Residence'\n",
    "    'Residence': 'Residential',  # Standardising 'Residence' to 'Residential'\n",
    "    'Commercial/residence': 'Commercial',  # Grouping 'Commercial/residence' with 'Commercial'\n",
    "    'Mobile': 'Transport',  # Merging 'Mobile' with 'Transport'\n",
    "    ' ': np.nan,  # Converting blank spaces to NaN\n",
    "    'nan': np.nan  # Converting 'nan' (string) to NaN\n",
    "})\n",
    "\n",
    "df['Location Category'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Location Sensitivity'`: Standardising "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistency in the `'Location Sensitivity'` column, the following adjustments are made:\n",
    "- All values are converted to lowercase to eliminate any case inconsistencies.\n",
    "- Leading and trailing spaces are removed from the entries to ensure uniformity.\n",
    "\n",
    "These steps help standardise the column, making the data cleaner and more consistent for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location Sensitivity\n",
       "High      264\n",
       "Low       115\n",
       "Medium     74\n",
       "NaN        36\n",
       "low         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location Sensitivity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in 'Location Sensitivity' to lowercase to standardise the case\n",
    "df['Location Sensitivity'] = df['Location Sensitivity'].str.lower()\n",
    "# Remove any leading or trailing spaces from the 'Location Sensitivity' values\n",
    "df['Location Sensitivity'] = df['Location Sensitivity'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Influencing Event/Event'`: Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Influencing Event/Event'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'Influencing Event/Event'` column contains **170 unique values**. Given the high number of distinct events, it is decided that this column will not be changed. The variety in values is important for the analysis, and modifying them may lead to the loss of valuable distinctions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Target Type'`: Standardising \n",
    "\n",
    "The following values in the `'Target Type'` column are merged to standardise the data:\n",
    "- 'civilian' is merged with 'Civilian'.\n",
    "- 'Government official' is standardised to 'Government Official'.\n",
    "- 'Army' is merged with 'Military'.\n",
    "- Variations of 'religious' are standardised to 'Religious', including 'Shia sect'.\n",
    "- 'foreigner' is merged with 'Foreigner'.\n",
    "- Variations of 'police', including 'Police & Rangers' and 'Rangers', are consolidated under 'Police'.\n",
    "- 'advocates (lawyers)' and 'Civilian Judges' are merged into 'Judges & lawyers'.\n",
    "- 'Children/Women' is merged into 'Civilian'.\n",
    "\n",
    "These changes help ensure consistency in the data, making it easier to analyse and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Foreigner', 'Media', 'Religious', 'Military',\n",
       "       'Government Official', 'civilian', 'Civilian', 'Police',\n",
       "       'Government official', 'police', 'Children/Women',\n",
       "       'Anti-Militants', 'foreigner', 'Unknown', 'religious', nan,\n",
       "       'Rangers', 'Police & Rangers', 'Civilian & Police', 'Army',\n",
       "       'Frontier Corps ', 'advocates (lawyers)', 'Civilian Judges',\n",
       "       'Shia sect', 'Judges & lawyers'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise and merge values in the 'Target Type' column\n",
    "df['Target Type'] = df['Target Type'].replace({\n",
    "    'civilian': 'Civilian',  # Merging case inconsistency for 'civilian'\n",
    "    'Government official': 'Government Official',  # Merging case inconsistency\n",
    "    'Army': 'Military',  # Merging 'Army' with 'Military'\n",
    "    'religious': 'Religious',  # Merging case inconsistency\n",
    "    'foreigner': 'Foreigner',  # Merging case inconsistency\n",
    "    'police': 'Police',  # Merging case inconsistency for 'police'\n",
    "    'Police & Rangers': 'Police',  # Merging 'Police & Rangers' with 'Police'\n",
    "    'Rangers': 'Police',  # Merging 'Rangers' with 'Police'\n",
    "    'advocates (lawyers)': 'Judges & lawyers',  # Merging with 'Judges & lawyers'\n",
    "    'Civilian Judges': 'Judges & lawyers',  # Merging with 'Judges & lawyers'\n",
    "    'Children/Women': 'Civilian',  # Merging 'Children/Women' with 'Civilian'\n",
    "    'Shia sect': 'Religious',  # Merging 'Shia sect' with 'Religious'\n",
    "    'Unknown': np.nan\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Targeted Sect if any'`: Standardising\n",
    "\n",
    "The following values in the `'Targeted Sect if any'` column are merged to standardise the data:\n",
    "- 'shiite' is standardised to 'Shiite' to correct case inconsistency.\n",
    "- 'Shiite/sunni' is merged into 'Shiite/Sunni' to represent the mixed reference to both sects.\n",
    "\n",
    "These changes help ensure consistency in the data, making it cleaner and more interpretable for analysis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Targeted Sect if any\n",
       "Shiite          38\n",
       "Sunni           38\n",
       "Christian        9\n",
       "shiite           9\n",
       "Shiite/sunni     1\n",
       "Jews             1\n",
       "Ahmedi           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Targeted Sect if any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise and merge values in the 'Religion' or 'Sect' column\n",
    "df['Targeted Sect if any'] = df['Targeted Sect if any'].replace({\n",
    "    'shiite': 'Shiite',  # Merging case inconsistency for 'Shiite'\n",
    "    'Shiite/sunni': 'Shiite/Sunni',  # Merging 'Shiite/sunni' to 'Mixed' or consider another approach\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `'Hospital Names'`: Reviewing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'Hospital Names'` column contains **237 unique values**, and while no changes will be made to this column at this stage, it could prove useful to standardise or clean it if required for future analysis. In some cases, multiple hospital names appear in a single entry, which could lead to further data cleaning or merging in the future, depending on the analysis needs. For now, the column will remain unchanged, but it may be revisited later if the need arises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Hospital Names'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Columns to Categorical Data Types\n",
    "\n",
    "To optimise the dataset for analysis, several columns have been converted to categorical data types. This helps improve memory usage and performance when filtering, grouping, or aggregating data. The following columns have been categorised:\n",
    "\n",
    "- `'Blast Day Type'` with three categories: `Working Day`, `Weekend`, and `Holiday`.\n",
    "- `'Holiday Type'`, which contains multiple holiday types, enabling efficient grouping.\n",
    "- `'City'` with 61 unique cities.\n",
    "- `'Province'` with 6 unique provinces.\n",
    "- `'Location Category'` with 17 unique categories.\n",
    "- `'Location Sensitivity'` has been converted to an ordered categorical type with three levels: `low < medium < high`.\n",
    "- `'Target Type'` with 11 unique target types.\n",
    "- `'Targeted Sect if any'` with 6 unique sects.\n",
    "- `'Open/Closed Space'` with two possible values: `open` and `closed`.\n",
    "\n",
    "These conversions ensure the data is well-structured for analysis and will lead to more efficient processing when working with the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to categorical data types\n",
    "df['Blast Day Type'] = df['Blast Day Type'].astype('category')  # 3 categories (Working Day, Weekend, Holiday)\n",
    "df['Holiday Type'] = df['Holiday Type'].astype('category')  # Multiple holiday types, useful for grouping\n",
    "df['City'] = df['City'].astype('category')  # 61 unique cities, converting to categorical\n",
    "df['Province'] = df['Province'].astype('category')  # 6 unique provinces\n",
    "df['Location Category'] = df['Location Category'].astype('category')  # 17 unique categories\n",
    "df['Location Sensitivity'] = pd.Categorical(df['Location Sensitivity'], categories=['low', 'medium', 'high'], ordered=True)  # Ordered categories (low < medium < high)\n",
    "df['Target Type'] = df['Target Type'].astype('category')  # 11 unique target types\n",
    "df['Targeted Sect if any'] = df['Targeted Sect if any'].astype('category')  # 6 unique sects\n",
    "df['Open/Closed Space'] = df['Open/Closed Space'].astype('category')  # 2 values (open, closed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Islamic Date</th>\n",
       "      <th>Blast Day Type</th>\n",
       "      <th>Holiday Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>City</th>\n",
       "      <th>Province</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Category</th>\n",
       "      <th>Location Sensitivity</th>\n",
       "      <th>Open/Closed Space</th>\n",
       "      <th>Influencing Event/Event</th>\n",
       "      <th>Target Type</th>\n",
       "      <th>Targeted Sect if any</th>\n",
       "      <th>Explosive Weight (max)</th>\n",
       "      <th>Hospital Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336</td>\n",
       "      <td>492</td>\n",
       "      <td>72</td>\n",
       "      <td>281</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>489</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>187</td>\n",
       "      <td>465</td>\n",
       "      <td>97</td>\n",
       "      <td>169</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>216</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>483</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5 Rajab 1428 A.H</td>\n",
       "      <td>Working Day</td>\n",
       "      <td>General Holiday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>peshawar</td>\n",
       "      <td>kpk</td>\n",
       "      <td>Imambargah</td>\n",
       "      <td>Police</td>\n",
       "      <td>high</td>\n",
       "      <td>open</td>\n",
       "      <td>Sectarian strife</td>\n",
       "      <td>Military</td>\n",
       "      <td>Shiite</td>\n",
       "      <td>6kg</td>\n",
       "      <td>Lady Reading Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>323</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>264</td>\n",
       "      <td>329</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Islamic Date Blast Day Type     Holiday Type     Time      City  \\\n",
       "count                336            492               72      281       492   \n",
       "unique               301              3               13      216        61   \n",
       "top     5 Rajab 1428 A.H    Working Day  General Holiday  Evening  peshawar   \n",
       "freq                   3            350               45       12        74   \n",
       "\n",
       "       Province    Location Location Category Location Sensitivity  \\\n",
       "count       492         489               456                  456   \n",
       "unique        6         483                18                    3   \n",
       "top         kpk  Imambargah            Police                 high   \n",
       "freq        323           3                90                  264   \n",
       "\n",
       "       Open/Closed Space Influencing Event/Event Target Type  \\\n",
       "count                456                     187         465   \n",
       "unique                 2                     169          11   \n",
       "top                 open        Sectarian strife    Military   \n",
       "freq                 329                       7         117   \n",
       "\n",
       "       Targeted Sect if any Explosive Weight (max)         Hospital Names  \n",
       "count                    97                    169                    294  \n",
       "unique                    6                    112                    236  \n",
       "top                  Shiite                    6kg  Lady Reading Hospital  \n",
       "freq                     47                      8                     20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.describe(include= ['category','object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '2.5 Kg', '30kg in each car', '2kg', '10-15 kg', '5 kg',\n",
       "       '10 kg ', '5 to 6 Kg', '10 to 15 kg', 'more than 5Kg', '5 to 6 kg',\n",
       "       '15 kg', '3 kg explosive and 3kg ball bearings', '6-7kg', '4-5kg',\n",
       "       '50kg', '30kg ', '100Kg', '150Kg', '1000 Kg', ' 8 Kg', '60Kg',\n",
       "       '8 ft deep crater', '40 kg', '7 or 8Kg', ' 10 kg ', '8Kg', '100kg',\n",
       "       '100', '85', '125 kg', '5kg', '160', '500 Kg', '24Kg', '10Kg',\n",
       "       '20 Kg', '12Kg', '12 Kg', '150 kg ', '180Kg', '100 Kg', '70 kg ',\n",
       "       '16 Kg', '15Kg', '10 Kg', '7Kg ', '400Kg', '200Kg', '50-60Kg',\n",
       "       '250Kg', '1000 KG', '250 kg', '600 kg', '40Kg', '5Kg', ' 12 kg',\n",
       "       '600Kg', '12 kg', '14 kg', '8 kg', '300 kg', '20 kg ', '10 kg',\n",
       "       '20Kg', ' 6 kg', '1200Kg', '12 kg ', '1000 Kg ', '400 KG',\n",
       "       '1000 kg', '7Kg', '9Kg', '16Kg', '250kg', '8kg', '180kg',\n",
       "       '16-20kg', '300kg', '450kg', '7kg', '60kg', '500 kg', '5-6kg',\n",
       "       '3kg', '6kg', '6Kg', '100-110kg', '30kg', '7kg-8kg', '100kg-150kg',\n",
       "       '4kg-5kg', '12kg', '600kg-800kg', '4kg-6kg', '1000kg', '7-8kg',\n",
       "       '6-7Kg', '20-25kg', '25-30kg', '14kg', '10kg', '45KG', '15KG',\n",
       "       '13KG', '8KG', '8-10KG', '6KG', '8-10 KG', ' 20 KG', '15 KG',\n",
       "       '75KG', '25KG'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Explosive Weight (max)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(355)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Explosive Weight (max)'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan,    2.5,    2. ,    5. ,   10. ,   15. ,   50. ,   30. ,\n",
       "        100. ,  150. , 1000. ,    8. ,   60. ,   40. ,   85. ,  125. ,\n",
       "        160. ,  500. ,   24. ,   20. ,   12. ,  180. ,   70. ,   16. ,\n",
       "          7. ,  400. ,  200. ,  250. ,   14. ,  300. ,    6. , 1200. ,\n",
       "          9. ,  450. ,    3. ,   45. ,   13. ,   75. ,   25. ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace variations of 'kg' (e.g., 'kg', 'Kg', 'KG') with an empty string ''\n",
    "df['Explosive Weight (max)'] = df['Explosive Weight (max)'].str.strip()\n",
    "df['Explosive Weight (max)'] = df['Explosive Weight (max)'].str.replace(r'[kK][gG]$', '', regex=True)\n",
    "df['Explosive Weight (max)'] = df['Explosive Weight (max)'].str.strip()\n",
    "\n",
    "replacement_dict = {\n",
    "    '30kg in each car': 30,\n",
    "    '10-15': 12.5,\n",
    "    '7-8': 7.5,\n",
    "    '100-110': 105,\n",
    "    '5 to 6': 5.5,\n",
    "    '10 to 15': 12.5,\n",
    "    '5 to 6 Kg': 5.5,\n",
    "    '20-25': 22.5,\n",
    "    '25-30': 27.5,\n",
    "    '4-5': 4.5,\n",
    "    '50-60': 55,\n",
    "    '6-7': 6.5,\n",
    "    '3 kg explosive and 3kg ball bearings': 6,  # Assuming the weight is 6kg\n",
    "    '7kg-8': 7.5,\n",
    "    '100kg-150': 125,\n",
    "    '600kg-800': 700,\n",
    "    '4kg-5': 4.5,\n",
    "    '1000kg': 1000,\n",
    "    '7-8kg': 7.5,\n",
    "    '4kg-6': 5,  # Average of 4-6\n",
    "    '16-20kg': 18,  # Average of 16-20\n",
    "    '600': 600,\n",
    "    '12kg': 12,\n",
    "    '8 ft deep crater': np.nan,  # Replace with NaN for this specific case\n",
    "    'more than 5':5,\n",
    "    '7 or 8':7.8,\n",
    "    '5-6':5.5,\n",
    "    '16-20':18\n",
    "}\n",
    "\n",
    "df['Explosive Weight (max)'] = df['Explosive Weight (max)'].replace(replacement_dict)\n",
    "df['Explosive Weight (max)'] = pd.to_numeric(df['Explosive Weight (max)'], errors='coerce')\n",
    "df['Explosive Weight (max)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Explosive Weight (max)\n",
       "2.5        1\n",
       "2.0        2\n",
       "5.0        7\n",
       "10.0      16\n",
       "15.0       9\n",
       "50.0       3\n",
       "30.0       2\n",
       "100.0      7\n",
       "150.0      2\n",
       "1000.0     6\n",
       "8.0       14\n",
       "60.0       4\n",
       "40.0       2\n",
       "85.0       1\n",
       "125.0      1\n",
       "160.0      1\n",
       "500.0      2\n",
       "24.0       1\n",
       "20.0       5\n",
       "12.0       9\n",
       "180.0      2\n",
       "70.0       1\n",
       "16.0       2\n",
       "7.0        3\n",
       "400.0      3\n",
       "200.0      1\n",
       "250.0      5\n",
       "14.0       2\n",
       "300.0      4\n",
       "6.0       11\n",
       "1200.0     1\n",
       "9.0        1\n",
       "450.0      1\n",
       "3.0        1\n",
       "45.0       1\n",
       "13.0       1\n",
       "75.0       1\n",
       "25.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Explosive Weight (max)'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Analysis Base)",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
